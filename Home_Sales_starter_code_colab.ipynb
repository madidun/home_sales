{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"a_KW73O2e3dw","executionInfo":{"status":"ok","timestamp":1686068934094,"user_tz":240,"elapsed":10,"user":{"displayName":"Umeadi Dungor","userId":"05630620712507359910"}}},"outputs":[],"source":["import os\n","# Find the latest version of spark 3.x  from http://www.apache.org/dist/spark/ and enter as the spark version\n","# For example:\n","# spark_version = 'spark-3.3.1'\n","spark_version = 'spark-3.4.0'\n","os.environ['spark-3.4.0']= 'spark-3.4.0'\n"]},{"cell_type":"code","source":["# Set Environment Variables\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = f\"/content/{'spark-3.4.0'}-bin-hadoop3\""],"metadata":{"id":"u59qeGB-jj3a","executionInfo":{"status":"ok","timestamp":1686068934095,"user_tz":240,"elapsed":9,"user":{"displayName":"Umeadi Dungor","userId":"05630620712507359910"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# Install Spark and Java\n","!apt-get update\n","!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n","!wget -q http://www.apache.org/dist/spark/$'spark-3.4.0'/$'spark-3.4.0'-bin-hadoop3.tgz\n","!tar xf $'spark-3.4.0'-bin-hadoop3.tgz\n","!pip install -q findspark"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PRcexVh5jKvA","executionInfo":{"status":"ok","timestamp":1686068993803,"user_tz":240,"elapsed":59716,"user":{"displayName":"Umeadi Dungor","userId":"05630620712507359910"}},"outputId":"ee506317-cc8c-4662-84ba-e6806d18becd"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease [3,622 B]\n","Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease\n","Get:3 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ Packages [78.0 kB]\n","Get:4 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal InRelease [18.1 kB]\n","Get:5 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]\n","Hit:6 http://archive.ubuntu.com/ubuntu focal InRelease\n","Get:7 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]\n","Hit:8 http://ppa.launchpad.net/cran/libgit2/ubuntu focal InRelease\n","Get:9 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease [18.1 kB]\n","Get:10 http://security.ubuntu.com/ubuntu focal-security/universe amd64 Packages [1,057 kB]\n","Get:11 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]\n","Hit:12 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal InRelease\n","Get:13 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [1,352 kB]\n","Get:14 http://security.ubuntu.com/ubuntu focal-security/main amd64 Packages [2,774 kB]\n","Hit:15 http://ppa.launchpad.net/ubuntugis/ppa/ubuntu focal InRelease\n","Get:16 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [3,253 kB]\n","Get:17 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal/main Sources [2,589 kB]\n","Get:18 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal/main amd64 Packages [1,222 kB]\n","Get:19 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal/main amd64 Packages [29.5 kB]\n","Fetched 12.7 MB in 7s (1,771 kB/s)\n","Reading package lists... Done\n"]}]},{"cell_type":"code","source":["# Start a SparkSession\n","import findspark\n","findspark.init()"],"metadata":{"id":"jxmDHXURlPJC","executionInfo":{"status":"ok","timestamp":1686068993805,"user_tz":240,"elapsed":13,"user":{"displayName":"Umeadi Dungor","userId":"05630620712507359910"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","execution_count":5,"metadata":{"id":"2XbWNf1Te5fM","executionInfo":{"status":"ok","timestamp":1686069002739,"user_tz":240,"elapsed":8945,"user":{"displayName":"Umeadi Dungor","userId":"05630620712507359910"}}},"outputs":[],"source":["# Import packages\n","from pyspark.sql import SparkSession\n","import time\n","\n","# Create a SparkSession\n","spark = SparkSession.builder.appName(\"SparkSQL\").getOrCreate()"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"wOJqxG_RPSwp","executionInfo":{"status":"ok","timestamp":1686069002740,"user_tz":240,"elapsed":15,"user":{"displayName":"Umeadi Dungor","userId":"05630620712507359910"}}},"outputs":[],"source":["# 1. Read in the AWS S3 bucket into a DataFrame.\n","from pyspark import SparkFiles\n","url = \"https://2u-data-curriculum-team.s3.amazonaws.com/dataviz-classroom/v1.2/22-big-data/home_sales_revised.csv\"\n","\n"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"RoljcJ7WPpnm","executionInfo":{"status":"ok","timestamp":1686069023030,"user_tz":240,"elapsed":20303,"user":{"displayName":"Umeadi Dungor","userId":"05630620712507359910"}}},"outputs":[],"source":["# 2. Create a temporary view of the DataFrame.\n","spark.sparkContext.addFile(url)\n","home_sales = spark.read.option('header', 'true').csv(SparkFiles.get(\"home_sales_revised.csv\"), inferSchema=True)\n","home_sales.createOrReplaceTempView(\"sales\") \n"]},{"cell_type":"markdown","source":[],"metadata":{"id":"zOOAA-6nfBuF"}},{"cell_type":"code","source":["home_sales"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7KhhDgO-YpHm","executionInfo":{"status":"ok","timestamp":1686069023031,"user_tz":240,"elapsed":37,"user":{"displayName":"Umeadi Dungor","userId":"05630620712507359910"}},"outputId":"dd227f4d-cced-4296-9f2a-479192f83855"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DataFrame[id: string, date: date, date_built: int, price: int, bedrooms: int, bathrooms: int, sqft_living: int, sqft_lot: int, floors: int, waterfront: int, view: int]"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","execution_count":9,"metadata":{"id":"L6fkwOeOmqvq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1686069027118,"user_tz":240,"elapsed":4119,"user":{"displayName":"Umeadi Dungor","userId":"05630620712507359910"}},"outputId":"1e40f0f7-8844-4640-998d-6bc817cd4f3c"},"outputs":[{"output_type":"stream","name":"stdout","text":["+----+-------------+\n","|YEAR|AVERAGE_PRICE|\n","+----+-------------+\n","|2022|    296363.88|\n","|2021|    301819.44|\n","|2020|    298353.78|\n","|2019|     300263.7|\n","+----+-------------+\n","\n"]}],"source":["# 3. What is the average price for a four bedroom house sold in each year rounded to two decimal places?\n","spark.sql(\"\"\"\n","    SELECT \n","      YEAR(date) AS YEAR,\n","      ROUND (AVG(price), 2) AS AVERAGE_PRICE \n","    FROM sales\n","    WHERE bedrooms = 4      \n","    GROUP BY YEAR\n","    ORDER BY YEAR DESC   \n","    \"\"\").show()\n"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"l8p_tUS8h8it","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1686069027119,"user_tz":240,"elapsed":41,"user":{"displayName":"Umeadi Dungor","userId":"05630620712507359910"}},"outputId":"248dfd54-14d6-4d80-da32-194ed7f403fa"},"outputs":[{"output_type":"stream","name":"stdout","text":["+----+-------------+\n","|YEAR|AVERAGE_PRICE|\n","+----+-------------+\n","|2022|    292725.69|\n","|2021|    294211.46|\n","|2020|    294204.16|\n","|2019|    287287.82|\n","+----+-------------+\n","\n"]}],"source":["# 4. What is the average price of a home for each year the home was built that have 3 bedrooms and 3 bathrooms rounded to two decimal places?\n","spark.sql(\"\"\"\n","    SELECT \n","      YEAR(date) AS YEAR,\n","      ROUND (AVG(price), 2) AS AVERAGE_PRICE \n","    FROM sales\n","    WHERE bedrooms = 3\n","    and bathrooms = 3      \n","    GROUP BY YEAR(date)\n","    ORDER BY YEAR DESC   \n","    \"\"\").show()\n"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"Y-Eytz64liDU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1686069028809,"user_tz":240,"elapsed":1726,"user":{"displayName":"Umeadi Dungor","userId":"05630620712507359910"}},"outputId":"ebebc8fa-f6d3-4a86-9b1e-c105db4d2bb5"},"outputs":[{"output_type":"stream","name":"stdout","text":["+----+-------------+\n","|YEAR|AVERAGE_PRICE|\n","+----+-------------+\n","|2022|    290242.99|\n","|2021|    296330.96|\n","|2020|    292289.09|\n","|2019|    289859.14|\n","+----+-------------+\n","\n"]}],"source":["# 5. What is the average price of a home for each year built that have 3 bedrooms, 3 bathrooms, with two floors,\n","# and are greater than or equal to 2,000 square feet rounded to two decimal places?\n","spark.sql(\"\"\"\n","    SELECT \n","      YEAR(date) AS YEAR,\n","      ROUND (AVG(price), 2) AS AVERAGE_PRICE \n","    FROM sales\n","    WHERE bedrooms = 3\n","    and bathrooms = 3  \n","    and floors = 2\n","    and sqft_living >= 2000   \n","    GROUP BY YEAR(date)\n","    ORDER BY YEAR DESC   \n","    \"\"\").show()\n"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GUrfgOX1pCRd","outputId":"d5722395-0e68-4c49-ac55-ae80b2d4b367","executionInfo":{"status":"ok","timestamp":1686069301861,"user_tz":240,"elapsed":906,"user":{"displayName":"Umeadi Dungor","userId":"05630620712507359910"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["+-------------+\n","|AVERAGE_PRICE|\n","+-------------+\n","|    473796.26|\n","+-------------+\n","\n","--- 0.6486926078796387 seconds ---\n"]}],"source":["# 6. What is the \"view\" rating for the average price of a home, rounded to two decimal places, where the homes are greater than\n","# or equal to $350,000? Although this is a small dataset, determine the run time for this query.\n","\n","start_time = time.time()\n","\n","spark.sql(\"\"\"\n"," SELECT ROUND(AVG(price), 2) AS AVERAGE_PRICE\n"," FROM sales \n"," WHERE price >= 350000\n"," \"\"\").show()\n","\n","end_time = time.time()\n","\n","\n","\n","print(\"--- %s seconds ---\" % (time.time() - start_time))"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"KAhk3ZD2tFy8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1686071886802,"user_tz":240,"elapsed":2555,"user":{"displayName":"Umeadi Dungor","userId":"05630620712507359910"}},"outputId":"222077b4-ed8b-4fc7-8401-eddaee4444d2"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["DataFrame[]"]},"metadata":{},"execution_count":25}],"source":["# 7. Cache the the temporary table home_sales.\n","spark.sql(\"cache table sales\") \n"]},{"cell_type":"code","execution_count":27,"metadata":{"id":"4opVhbvxtL-i","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1686071902623,"user_tz":240,"elapsed":469,"user":{"displayName":"Umeadi Dungor","userId":"05630620712507359910"}},"outputId":"eda68b5b-408c-4931-caf7-0d7dd4df711f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":27}],"source":["# 8. Check if the table is cached.\n","spark.catalog.isCached('sales')"]},{"cell_type":"code","execution_count":79,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":130},"id":"5GnL46lwTSEk","outputId":"4c1da163-4418-45f5-99ce-3c9083d4be83","executionInfo":{"status":"error","timestamp":1686084846498,"user_tz":240,"elapsed":313,"user":{"displayName":"Umeadi Dungor","userId":"05630620712507359910"}}},"outputs":[{"output_type":"error","ename":"IndentationError","evalue":"ignored","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-79-a0066036bc23>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    spark.sql(\"\"\"\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"]}],"source":["# 9. Using the cached data, run the query that filters out the view ratings with average price \n","#  greater than or equal to $350,000. Determine the runtime and compare it to uncached runtime.\n","\n","start_time = time.time()\n","\n"," spark.sql(\"\"\"\n"," SELECT VIEW_RATING\n"," FROM sales \n"," WHERE price >= 350000\n"," \"\"\").show() \n","\n","\n","end_time = time.time() \n","\n","\n","\n","print(\"--- %s seconds ---\" % (time.time() - start_time))\n"]},{"cell_type":"code","execution_count":61,"metadata":{"id":"Qm12WN9isHBR","executionInfo":{"status":"ok","timestamp":1686078221068,"user_tz":240,"elapsed":3220,"user":{"displayName":"Umeadi Dungor","userId":"05630620712507359910"}}},"outputs":[],"source":["# 10. Partition by the \"date_built\" field on the formatted parquet home sales data \n","home_sales.write.parquet('date_built', mode='overwrite') "]},{"cell_type":"code","execution_count":78,"metadata":{"id":"AZ7BgY61sRqY","executionInfo":{"status":"ok","timestamp":1686084831849,"user_tz":240,"elapsed":323,"user":{"displayName":"Umeadi Dungor","userId":"05630620712507359910"}}},"outputs":[],"source":["# 11. Read the parquet formatted data.\n","home_sales=spark.read.parquet('date_built') "]},{"cell_type":"code","execution_count":63,"metadata":{"id":"J6MJkHfvVcvh","executionInfo":{"status":"ok","timestamp":1686078581144,"user_tz":240,"elapsed":496,"user":{"displayName":"Umeadi Dungor","userId":"05630620712507359910"}}},"outputs":[],"source":["# 12. Create a temporary table for the parquet data.\n","home_sales.createOrReplaceTempView(\"data_built\")"]},{"cell_type":"code","execution_count":65,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":415},"id":"G_Vhb52rU1Sn","outputId":"849be7c9-6a63-4cd7-dff8-6ab475b49549","executionInfo":{"status":"error","timestamp":1686082619599,"user_tz":240,"elapsed":8,"user":{"displayName":"Umeadi Dungor","userId":"05630620712507359910"}}},"outputs":[{"output_type":"error","ename":"AnalysisException","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-65-ce9667d54781>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mhome_sales\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhome_sales\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'average_price'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m350000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'view_rating'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'average_price'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupBy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'view_rating'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'average_price'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'avg'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumnRenamed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'avg(average_price)'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'average_price'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/spark-3.4.0-bin-hadoop3/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   2926\u001b[0m         \"\"\"\n\u001b[1;32m   2927\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2928\u001b[0;31m             \u001b[0mjc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2929\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2930\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/spark-3.4.0-bin-hadoop3/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1323\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/spark-3.4.0-bin-hadoop3/python/pyspark/errors/exceptions/captured.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    173\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAnalysisException\u001b[0m: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `average_price` cannot be resolved. Did you mean one of the following? [`id`, `date`, `date_built`, `price`, `bedrooms`, `bathrooms`, `sqft_living`, `sqft_lot`, `floors`, `waterfront`, `view`]."]}],"source":[" 13. Run the query that filters out the view ratings with average price of greater than or equal to $350,000 \n","# with the parquet DataFrame. Round your average to two decimal places. \n","# Determine the runtime and compare it to the cached version.\n","\n","start_time = time.time()\n","\n","\n","\n","print(\"--- %s seconds ---\" % (time.time() - start_time))"]},{"cell_type":"markdown","source":[],"metadata":{"id":"wNE-f8VRWo3N"}},{"cell_type":"code","execution_count":66,"metadata":{"id":"hjjYzQGjtbq8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1686084141824,"user_tz":240,"elapsed":332,"user":{"displayName":"Umeadi Dungor","userId":"05630620712507359910"}},"outputId":"d8ea2a43-fec1-48ae-cc37-c488e003ddba"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["DataFrame[]"]},"metadata":{},"execution_count":66}],"source":["# 14. Uncache the home_sales temporary table.\n","spark.sql(\"uncache table sales\")"]},{"cell_type":"code","execution_count":77,"metadata":{"id":"Sy9NBvO7tlmm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1686084494497,"user_tz":240,"elapsed":302,"user":{"displayName":"Umeadi Dungor","userId":"05630620712507359910"}},"outputId":"d10b30fe-52ba-4c64-ece0-e781102e7b99"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["False"]},"metadata":{},"execution_count":77}],"source":["# 15. Check if the home_sales is no longer cached\n","spark.catalog.isCached(\"sales\") "]}],"metadata":{"colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"},"nteract":{"version":"0.28.0"}},"nbformat":4,"nbformat_minor":0}